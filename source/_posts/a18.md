title: Spark Memory Management
date: 2020-09-10
tags: [spark]
toc: true
---
æœ¬æ–‡ä¸»è¦æ˜¯å¯¹Sparkçš„å†…å­˜ç®¡ç†æ¨¡å—è¿›è¡Œäº†ä»£ç èµ°è¯»ï¼Œä»ä¸šåŠ¡é€»è¾‘ä¸ŠSparkå°†å†…å­˜åˆ’åˆ†ä¸ºæ‰§è¡ŒåŒºï¼ˆExecutionåŒºï¼Œå†…å­˜ä¸»è¦ç”¨æ¥è¿›è¡Œshuffleï¼Œjoinï¼Œsortï¼Œaggregateçš„è®¡ç®—ï¼‰ã€å­˜å‚¨åŒºï¼ˆStorageåŒºï¼Œå†…å­˜ä¸»è¦ç”¨æ¥è¿›è¡Œç¼“å­˜å’Œdata transferï¼‰ã€‚ä¸ºäº†ä¼˜åŒ–JVMå†…å­˜ç³»ç»Ÿçš„ä¸€äº›é—®é¢˜ï¼Œåœ¨å †å†…å­˜å’Œå †å¤–å†…å­˜çš„åŸºç¡€ä¸ŠæŠ½è±¡äº†Tungstenå†…å­˜ç³»ç»Ÿã€‚æ–‡ä¸­å¯¹æ¶‰åŠåˆ°çš„å†…çš„å…³é”®æ–¹æ³•è¿›è¡Œäº†åˆ†æã€‚

## ä»£ç æ¸…å•
- org.apache.spark.memory.MemoryManager
- org.apache.spark.memory.UnifiedMemoryManager
- org.apache.spark.memory.MemoryPool
- org.apache.spark.memory.ExecutionMemoryPool
- org.apache.spark.memory.StorageMemoryPool
- org.apache.spark.memory.MemoryConsumer
- org.apache.spark.memory.TaskMemoryManager
- org.apache.spark.unsafe.memory.MemoryLocation
- org.apache.spark.unsafe.memory.MemoryBlock
- org.apache.spark.unsafe.memory.MemoryAllocator
- org.apache.spark.unsafe.memory.HeapMemoryAllocator
- org.apache.spark.unsafe.memory.UnsafeMemoryAllocator
- org.apache.spark.storage.memory.MemoryStore

## æ€»è§ˆ
![a18-1](/images/a18-1.jpg)
å…¨å±€åªæœ‰å”¯ä¸€ä¸€ä¸ªMemoryManagerï¼Œé‡Œé¢ç»´æŠ¤äº†4ä¸ªPoolã€‚ä»ä¸šåŠ¡ä¸Šåˆ†ä¸ºExecutionå’ŒStorageï¼Œä»å­˜å‚¨ä½ç½®åˆ†ä¸ºOnHeapå’ŒOffHeapã€‚æ¯ä¸ªtaskéœ€è¦ä½¿ç”¨å¤šä¸ªæ•°æ®ç»“æ„ï¼Œæ¯ä¸ªæ•°æ®ç»“æ„éƒ½æ˜¯ä¸€ä¸ª`MemoryConsumer`çš„å®ç°ï¼Œæ¯ä¸ªtaskçš„è¿™äº›consumeréƒ½é€šè¿‡`TaskMemoryManager`è¿›è¡Œç®¡ç†ï¼Œå¤šä¸ª`TaskMemoryManager`å…±åŒç»´æŠ¤ä¸€ä¸ª`Tungsten`çš„é¡µç»“æ„ã€‚

## Tungsten
ä¸ºäº†è§£å†³JVMå¯¹è±¡å­˜å‚¨æ—¶çš„overheadé—®é¢˜ï¼Œä»¥åŠGCé€ æˆçš„æ€§èƒ½æŸè€—ï¼Œè€Œæå‡ºäº†ä¸€ä¸ªæ–°çš„å†…å­˜æ¨¡å‹ã€‚æä¾›ä¸€å¥—åƒC/C++ä¸€æ ·å¯ä»¥ç›´æ¥æ“ä½œå†…å­˜çš„æ¥å£ï¼ˆå®é™…æ“ä½œçš„æ˜¯å †å¤–å†…å­˜ï¼‰ï¼Œå†ä¸ºäº†é€šç”¨æ€§æä¾›äº†æ›´é«˜å±‚çš„æ¥å£å°†å †å†…å­˜å’Œå †å¤–å†…å­˜è¿›è¡Œäº†ç»Ÿä¸€ã€‚

```java
public class MemoryLocation {

  @Nullable
  Object obj;

  long offset;

  public MemoryLocation(@Nullable Object obj, long offset) {
    this.obj = obj;
    this.offset = offset;
  }

  public MemoryLocation() {
    this(null, 0);
  }

  public void setObjAndOffset(Object newObj, long newOffset) {
    this.obj = newObj;
    this.offset = newOffset;
  }

  public final Object getBaseObject() {
    return obj;
  }

  public final long getBaseOffset() {
    return offset;
  }
}
```

```java
public class MemoryBlock extends MemoryLocation {
	private final long length;
	public int pageNumber = NO_PAGE_NUMBER;
	...
}
```
Tungstenæä¾›äº†ä¸€å¥—ç±»ä¼¼æ“ä½œç³»ç»Ÿé¡µå†…å­˜ç®¡ç†ä¸€æ ·çš„ç»“æ„ï¼Œæ¯é¡µä¼šå­˜å‚¨ä¸€ä¸ª`MemoryBlock`ç»“æ„ã€‚
`length`æ˜¯æ•´ä¸ªBlockå®é™…å ç”¨çš„å†…å­˜å¤§å°ï¼Œ`pageNumber`æ˜¯åœ¨é¡µæ•°ç»„ä¸­çš„indexä½ç½®ã€‚`MemoryLocation`ç»Ÿä¸€äº†å †å†…å¤–å†…å­˜çš„å¯»å€ï¼Œå¦‚æœæ˜¯off-heapï¼Œåˆ™`obj`ä¸ºnullï¼Œ`offset`ä¸ºç»å¯¹å†…å­˜åœ°å€ï¼›å¦‚æœæ˜¯on-heapï¼Œåˆ™`obj`ä¸ºå¯¹è±¡çš„åŸºåœ°å€ï¼Œ`offset`ä¸ºåç§»é‡ã€‚æ‰€ä»¥åœ¨å®é™…ä½¿ç”¨è¿‡ç¨‹å½“ä¸­å°±éœ€è¦åœ¨ç‰©ç†åœ°å€ä¸`pageNumber`,`offsetInPage`ä¹‹é—´è¿›è¡Œè½¬æ¢ï¼š
- on-heap: `address = page.obj + page.offset + inPageOffset`
- off-heap: `address = page.offset + inPageOffset`

ä½†æ˜¯åœ¨è¿™å¥—ç»“æ„ä¸­ç‰©ç†åœ°å€ä¸ä¼šç›´æ¥çš„å­˜å‚¨ï¼Œ`pageNumer` + `offsetInPage`çš„ç»„åˆå°±èƒ½å”¯ä¸€çš„å®šä½ä¸€ä¸ªå€¼çš„ä½ç½®ï¼Œæ‰€ä»¥æä¾›äº†ä¸€ä¸ªç¼–ç æ–¹æ³•ç”¨64ä½çš„longå€¼å­˜å‚¨è¿™ä¸ªåæ ‡ï¼Œå‰13ä½æ˜¯pageNumberï¼Œå51ä½æ˜¯inPageOffsetã€‚åœ¨`TaskMemoryManager`å½“ä¸­æä¾›äº†å¤šä¸ªè½¬æ¢çš„æ–¹æ³•ï¼š

- `long encodePageNumberAndOffset(MemoryBlock page, long offsetInPage)`ï¼šç»™å®šé¡µå’Œé¡µå†…åç§»é‡è®¡ç®—encodeå€¼
- `long encodePageNumberAndOffset(int pageNumer, long offsetInPage)`ï¼šç»™å®šé¡µå·å’Œé¡µå†…åç§»é‡è®¡ç®—encodeå€¼
- `int decodePageNumber(long pagePlusOffsetAddress)`ï¼šç»™å®šencodeå€¼ï¼Œè§£ç pageNumber
- `long decodeOffset(long pagePlusOffsetAddress)`ï¼šç»™å®šencodeå€¼ï¼Œè§£ç offset
- `Object getPage(long pagePlusOffsetAddress)`ï¼šç»™å®šencodeå€¼ï¼Œè·å–é¡µ
- `long getOffsetInPage(long pagePlusOffsetAddress)`ï¼šç»™å®šencodeå€¼ï¼Œè·å–é¡µå†…åç§»

## Memory
### MemoryManager
è¯¥ç±»æ˜¯å†…å­˜ç®¡ç†çš„ç»Ÿç­¹ç±»ï¼Œå®šä¹‰äº†æ‰€æœ‰çš„å†…å­˜ç®¡ç†åŠ¨ä½œã€‚å› ä¸ºæ˜¯ä¸€ä¸ªæŠ½è±¡ç±»ï¼Œæ‰€ä»¥è¿™äº›åŠ¨ä½œæœ‰çš„ä¼šä¸‹æ”¾ç»™å®ç°ç±»å®ç°ï¼Œæœ‰äº›åŠ¨ä½œä¼šå§”æ‰˜`MemoryPool`ç±»å®ç°ã€‚ä¸‹é¢æ˜¯æ¥å£çš„åˆ†ç±»ï¼š

* è·å–å†…å­˜å¤§å°ï¼š
	* `abstract maxOnHeapStorageMemory`ï¼šè·å–StorageåŒºæœ€å¤§èƒ½ä½¿ç”¨çš„å †å†…å­˜å¤§å°ï¼ˆåŠ¨æ€å˜åŒ–çš„ï¼‰
	* `abstract maxOffHeapStorageMemory`ï¼šè·å–StorageåŒºæœ€å¤§èƒ½ä½¿ç”¨çš„å †å¤–å†…å­˜å¤§å°ï¼ˆåŠ¨æ€å˜åŒ–çš„ï¼‰
	* 	`storageMemoryUsed`: StorageåŒºå·²ä½¿ç”¨çš„å†…å­˜å¤§å°
	* `onHeapStorageMemoryUsed`ï¼šStorageåŒºå·²ä½¿ç”¨çš„å †å†…å­˜å¤§å°
	* `offHeapStorageMemoryUsed`ï¼šStorageåŒºå·²ä½¿ç”¨çš„å †å¤–å†…å­˜å¤§å°
	* `executionMemoryUsed`: ExecutionåŒºå·²ä½¿ç”¨çš„å†…å­˜å¤§å°
	* `onHeapExecutionMemoryUsed`ï¼šExecutionåŒºå·²ä½¿ç”¨çš„å †å†…å­˜å¤§å°
	* `offHeapExecutionMemoryUsed`ï¼šExecutionåŒºå·²ä½¿ç”¨çš„å †å¤–å†…å­˜å¤§å°
	* 	`getExecutionMemoryUsageForTask`ï¼šè·å–ä¸€ä¸ªtaskåœ¨ExecutionåŒºå ç”¨çš„å†…å­˜å¤§å°

* è·å–æ›´å¤šçš„å†…å­˜ç©ºé—´ï¼š
	* `abstract acquireStorageMemory(blockId: BlockId, numBytes: Long, memoryMode: MemoryMode)`ï¼šä¸ºä¸€ä¸ªBlockè·å–`numBytes`çš„StorageåŒºå†…å­˜ç©ºé—´ï¼Œå¦‚æœè·å–ä¸åˆ°è¶³å¤Ÿçš„ç©ºé—´å¯èƒ½ä¼šåˆ é™¤ä¸€ä¸ªå­˜åœ¨çš„Blockã€‚
	* `abstract acquireExecutionMemory(numBytes: Long, taskAttemptId: Long, memoryMode: MemoryMode)`ï¼šä¸ºä¸€ä¸ªtaskè·å–`numBytes`çš„ExecutionåŒºå†…å­˜ç©ºé—´ï¼Œå½“ä¸èƒ½è·å–åˆ°è¶³å¤Ÿæ‰§è¡Œçš„å†…å­˜ç©ºé—´æ—¶ï¼Œè¿™ä¸ªæ–¹æ³•ä¼šé˜»å¡ï¼Œç›´åˆ°è·å–åˆ°è¶³å¤Ÿå¤šçš„å†…å­˜ã€‚

* é‡Šæ”¾å†…å­˜ç©ºé—´ï¼š
	* `releaseAllExecutionMemoryForTask(taskAttemptId: Long)`ï¼šé‡Šæ”¾ä¸€ä¸ªtaskå ç”¨çš„æ‰€æœ‰ExecutionåŒºå†…å­˜ç©ºé—´
	* `releaseStorageMemory(numBytes: Long, memoryMode: MemoryMode)`ï¼šé‡Šæ”¾`numBytes`çš„StorageåŒºå†…å­˜ç©ºé—´
	* `releaseAllStorageMemory()`ï¼šé‡Šæ”¾æ‰€æœ‰çš„StorageåŒºå†…å­˜ç©ºé—´
	* `releaseUnrollMemory(numBytes: Long, memoryMode: MemoryMode)`ï¼šé‡Šæ”¾`numBytes`çš„ç”¨äºunroll blockçš„å†…å­˜ç©ºé—´

* `Tungsten`ç›¸å…³

### UnifiedMemoryManager
```scala
private[spark] class UnifiedMemoryManager(
    conf: SparkConf,
    val maxHeapMemory: Long,
    onHeapStorageRegionSize: Long,
    numCores: Int)
```
æ„é€ å‡½æ•°ä¸­çš„ï¼š
+ `maxHeapMemory`ï¼šæ˜¯å †å†…å­˜çš„æ€»å¤§å°
+ `onHeapStorageRegionSize`ï¼šæ˜¯å †å†…å­˜ä¸­StorageåŒºçš„èµ·å§‹å¤§å°

```scala
override def maxOnHeapStorageMemory: Long = synchronized {
  maxHeapMemory - onHeapExecutionMemoryPool.memoryUsed
}

override def maxOffHeapStorageMemory: Long = synchronized {
  maxOffHeapMemory - offHeapExecutionMemoryPool.memoryUsed
}
```
è¿™ä¸¤ä¸ªæ–¹æ³•å°±æ˜¯ç®€å•çš„è®¡ç®—ï¼Œä¸è¿‡`maxHeapMemory`æ˜¯åˆ›å»º`UnifiedMemoryManager`æ—¶ä¼ å…¥çš„å‚æ•°ï¼Œè€Œ`maxOffHeapMemory`æ˜¯ä»`spark.memory.offHeap.size`å‚æ•°ä¸­è¯»å…¥ã€‚

::acquireExecutionMemory::
`acquireExecutionMemory`ä¸­ä¸»è¦çš„ä»»åŠ¡å°±æ˜¯è¦ç»™å‡º`MemoryPool.acquireMemory()`ä¸­çš„ä¸¤ä¸ªå›è°ƒï¼Œä¸€ä¸ªæ˜¯è·å–æ›´å¤šçš„ExecutionåŒºå†…å­˜çš„å›è°ƒï¼Œä¸€ä¸ªæ˜¯è·å–ExecutionåŒºæœ€å¤šèƒ½è·å–åˆ°çš„å†…å­˜å¤§å°ã€‚

```scala
def maybeGrowExecutionPool(extraMemoryNeeded: Long): Unit = {
  if (extraMemoryNeeded > 0) {
    // There is not enough free memory in the execution pool, so try to reclaim memory from
    // storage. We can reclaim any free memory from the storage pool. If the storage pool
    // has grown to become larger than `storageRegionSize`, we can evict blocks and reclaim
    // the memory that storage has borrowed from execution.
    val memoryReclaimableFromStorage = math.max(
      storagePool.memoryFree,
      storagePool.poolSize - storageRegionSize)
    if (memoryReclaimableFromStorage > 0) {
      // Only reclaim as much space as is necessary and available:
      val spaceToReclaim = storagePool.freeSpaceToShrinkPool(
        math.min(extraMemoryNeeded, memoryReclaimableFromStorage))
      storagePool.decrementPoolSize(spaceToReclaim)
      executionPool.incrementPoolSize(spaceToReclaim)
    }
  }
}
```
ğŸ‘†è·å–æ›´å¤šçš„ExecutionåŒºå†…å­˜çš„å›è°ƒï¼Œè¿™é‡Œæœ€é‡è¦çš„æ˜¯è®¡ç®—å¯ä»¥å½’è¿˜å†…å­˜å¤§å°çš„é€»è¾‘ï¼Œåœ¨`memoryFree`ï¼ˆç©ºé—²çš„å†…å­˜å¤§å°ï¼‰å’Œ`poolSize-storageRegionSize`ï¼ˆå‘ExecutionsåŒºå€Ÿçš„å†…å­˜å¤§å°ï¼‰ä¸­å–ä¸€ä¸ªæ›´å¤§çš„å€¼ã€‚ç„¶åçœŸæ­£å½’è¿˜çš„å†…å­˜å¤§å°æ˜¯åœ¨`memoryReclaimableFromStorage`ï¼ˆå¯ä»¥å½’è¿˜çš„å†…å­˜å¤§å°ï¼‰å’Œ`extraMemoryNeeded`ï¼ˆExecutionsåŒºéœ€è¦æ‰©å¤§çš„å†…å­˜å¤§å°ï¼‰ä¹‹é—´å–ä¸€ä¸ªæ›´å°çš„å€¼ã€‚

è®¡ç®—å®Œæˆä»¥åéœ€è¦çœŸæ­£çš„è¿›è¡Œå†…å­˜æ“ä½œé‡Šæ”¾éœ€è¦çš„å†…å­˜ï¼Œè¯¥æ–¹æ³•åœ¨`StorageMemoryPool`ä¸­ï¼š
```scala
def freeSpaceToShrinkPool(spaceToFree: Long): Long = lock.synchronized {
  val spaceFreedByReleasingUnusedMemory = math.min(spaceToFree, memoryFree)
  val remainingSpaceToFree = spaceToFree - spaceFreedByReleasingUnusedMemory
  if (remainingSpaceToFree > 0) {
    // If reclaiming free memory did not adequately shrink the pool, begin evicting blocks:
    val spaceFreedByEviction =
      memoryStore.evictBlocksToFreeSpace(None, remainingSpaceToFree, memoryMode)
    // When a block is released, BlockManager.dropFromMemory() calls releaseMemory(), so we do
    // not need to decrement _memoryUsed here. However, we do need to decrement the pool size.
    spaceFreedByReleasingUnusedMemory + spaceFreedByEviction
  } else {
    spaceFreedByReleasingUnusedMemory
  }
}
````
å…ˆè®¡ç®—ç©ºé—²ç©ºé—´çš„å¤§å°ï¼Œå¦‚æœç©ºé—²ç©ºé—´å¤§äºç­‰äºéœ€è¦é‡Šæ”¾çš„ç©ºé—´å¤§å°ï¼Œåˆ™ä¸éœ€è¦è¿›è¡Œå†…å­˜å¯¹è±¡æ“ä½œã€‚å¦åˆ™çš„è¯ï¼Œéœ€è¦åˆ é™¤ä¸€äº›å†…å­˜Blockã€‚åˆ é™¤çš„æ–¹æ³•åœ¨`MemoryStore`ä¸­ï¼š
```scala
private[spark] def evictBlocksToFreeSpace(
    blockId: Option[BlockId],
    space: Long,
    memoryMode: MemoryMode): Long = {
  assert(space > 0)
  memoryManager.synchronized {
    var freedMemory = 0L
    val rddToAdd = blockId.flatMap(getRddId)
    val selectedBlocks = new ArrayBuffer[BlockId]
    def blockIsEvictable(blockId: BlockId, entry: MemoryEntry[_]): Boolean = {
      entry.memoryMode == memoryMode && (rddToAdd.isEmpty || rddToAdd != getRddId(blockId))
    }
    // This is synchronized to ensure that the set of entries is not changed
    // (because of getValue or getBytes) while traversing the iterator, as that
    // can lead to exceptions.
    entries.synchronized {
      val iterator = entries.entrySet().iterator()
      while (freedMemory < space && iterator.hasNext) {
        val pair = iterator.next()
        val blockId = pair.getKey
        val entry = pair.getValue
        if (blockIsEvictable(blockId, entry)) {
          // We don't want to evict blocks which are currently being read, so we need to obtain
          // an exclusive write lock on blocks which are candidates for eviction. We perform a
          // non-blocking "tryLock" here in order to ignore blocks which are locked for reading:
          if (blockInfoManager.lockForWriting(blockId, blocking = false).isDefined) {
            selectedBlocks += blockId
            freedMemory += pair.getValue.size
          }
        }
      }
    }

    def dropBlock[T](blockId: BlockId, entry: MemoryEntry[T]): Unit = {
      val data = entry match {
        case DeserializedMemoryEntry(values, _, _) => Left(values)
        case SerializedMemoryEntry(buffer, _, _) => Right(buffer)
      }
      val newEffectiveStorageLevel =
        blockEvictionHandler.dropFromMemory(blockId, () => data)(entry.classTag)
      if (newEffectiveStorageLevel.isValid) {
        // The block is still present in at least one store, so release the lock
        // but don't delete the block info
        blockInfoManager.unlock(blockId)
      } else {
        // The block isn't present in any store, so delete the block info so that the
        // block can be stored again
        blockInfoManager.removeBlock(blockId)
      }
    }

    if (freedMemory >= space) {
      var lastSuccessfulBlock = -1
      try {
        logInfo(s"${selectedBlocks.size} blocks selected for dropping " +
          s"(${Utils.bytesToString(freedMemory)} bytes)")
        (0 until selectedBlocks.size).foreach { idx =>
          val blockId = selectedBlocks(idx)
          val entry = entries.synchronized {
            entries.get(blockId)
          }
          // This should never be null as only one task should be dropping
          // blocks and removing entries. However the check is still here for
          // future safety.
          if (entry != null) {
            dropBlock(blockId, entry)
            afterDropAction(blockId)
          }
          lastSuccessfulBlock = idx
        }
        logInfo(s"After dropping ${selectedBlocks.size} blocks, " +
          s"free memory is ${Utils.bytesToString(maxMemory - blocksMemoryUsed)}")
        freedMemory
      } finally {
        // like BlockManager.doPut, we use a finally rather than a catch to avoid having to deal
        // with InterruptedException
        if (lastSuccessfulBlock != selectedBlocks.size - 1) {
          // the blocks we didn't process successfully are still locked, so we have to unlock them
          (lastSuccessfulBlock + 1 until selectedBlocks.size).foreach { idx =>
            val blockId = selectedBlocks(idx)
            blockInfoManager.unlock(blockId)
          }
        }
      }
    } else {
      blockId.foreach { id =>
        logInfo(s"Will not store $id")
      }
      selectedBlocks.foreach { id =>
        blockInfoManager.unlock(id)
      }
      0L
    }
  }
}
```
è¯¥ç±»å½“ä¸­æœ‰ä¸€ä¸ªå­˜å‚¨æ‰€æœ‰Blockçš„Mapï¼Œå³ï¼š
```scala
private val entries = new LinkedHashMap[BlockId, MemoryEntry[_]](32, 0.75f, true)
```
`LinkedHashMap`ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œæ‰€ä»¥æ¯æ¬¡æ“ä½œä¹‹å‰ä¹Ÿæ˜¯éœ€è¦åŠ é”ã€‚å¦‚æœæ²¡æœ‰è·å–åˆ°éœ€è¦é‡Šæ”¾çš„å†…å­˜ç©ºé—´å¤§å°åˆ™éå†Blockï¼Œåˆ¤æ–­éå†çš„Blockä¸éœ€è¦å­˜å‚¨çš„Blockæ˜¯å¦æ˜¯åŒä¸€ä¸ªå­˜å‚¨åŒºåŸŸï¼ˆè¿˜åˆ¤æ–­äº†éå†çš„Blockä¸éœ€è¦å­˜å‚¨çš„Blockæ˜¯å¦æ˜¯åŒä¸€ä¸ªï¼‰ï¼Œå¦‚æœé€šè¿‡äº†åˆ¤æ–­åˆ™éœ€è¦å…ˆå°†è¯¥Blocké”ä½ï¼ŒåŠ å…¥å€™é€‰åå•ã€‚

æ‰¾å¤Ÿæ‰€æœ‰çš„å€™é€‰è€…ä»¥åè¿˜æ²¡æœ‰è¾¾åˆ°éœ€è¦é‡Šæ”¾çš„å†…å­˜ç©ºé—´å¤§å°åˆ™å°†æ‰€æœ‰é”ä½çš„Blockè§£é”ï¼Œè¿”å›0ï¼Œè¡¨ç¤ºè¿™ä¸ªæ“ä½œå¤±è´¥ã€‚å¦‚æœè¾¾åˆ°äº†ï¼Œåˆ™å¼€å§‹é‡Šæ”¾å†…å­˜çš„è¿‡ç¨‹ã€‚å°†æ¯ä¸€ä¸ªBlockæ‰§è¡Œ`dropBlock`ï¼Œ`afterDropAction`çš„æ“ä½œã€‚åœ¨`dropBlock`ä¸­ä¼šåˆ é™¤è¯¥Blockæœ¬èº«çš„æ•°æ®ï¼ˆé™¤éBlockè¿˜åœ¨è¢«æ“ä½œï¼‰ï¼Œæ£€æŸ¥Blockæ˜¯å¦è¿˜åœ¨è¢«å…¶ä»–çš„storageå­˜å‚¨ï¼Œå¦‚æœæ˜¯çš„è¯å°±å…ˆä¸åˆ é™¤å…¶metadataï¼Œå¦åˆ™çš„è¯ç»§ç»­åˆ é™¤metadataã€‚`afterDropAction`æ˜¯ä¸ªhookï¼Œå¯ä»¥ç”±è°ƒç”¨æ–¹æŒ‡å®šåˆ é™¤ä¹‹åçš„åŠ¨ä½œã€‚å¦‚æœåœ¨åˆ é™¤è¿‡ç¨‹å½“ä¸­å¤±è´¥çš„è¯ï¼Œéœ€è¦å°†æ²¡æœ‰åˆ é™¤çš„Blockè§£é”ã€‚

```scala
def computeMaxExecutionPoolSize(): Long = {
  maxMemory - math.min(storagePool.memoryUsed, storageRegionSize)
}
```
ğŸ‘†è·å–ExecutionåŒºæœ€å¤šèƒ½è·å–åˆ°çš„å†…å­˜å¤§å°ï¼Œæ˜¯é€šè¿‡æœ€å¤§çš„å†…å­˜å¤§å°å‡å»StorageåŒºæœ€å¤§èƒ½å ç”¨çš„å†…å­˜å¤§å°ã€‚StorageåŒºèƒ½å ç”¨çš„ä¸Šé™æ˜¯`storageRegionSize`ã€‚

ä¸‹é¢æ¥çœ‹çœŸæ­£è¿›è¡Œå†…å­˜åˆ†é…çš„å‡½æ•°`acquireMemory`ï¼Œè¯¥æ–¹æ³•åœ¨`ExecutionMemoryPool`ä¸­ï¼š
```scala
private[memory] def acquireMemory(
    numBytes: Long,
    taskAttemptId: Long,
    maybeGrowPool: Long => Unit = (additionalSpaceNeeded: Long) => (),
    computeMaxPoolSize: () => Long = () => poolSize): Long = lock.synchronized {
  assert(numBytes > 0, s"invalid number of bytes requested: $numBytes")

  // TODO: clean up this clunky method signature

  // Add this task to the taskMemory map just so we can keep an accurate count of the number
  // of active tasks, to let other tasks ramp down their memory in calls to `acquireMemory`
  if (!memoryForTask.contains(taskAttemptId)) {
    memoryForTask(taskAttemptId) = 0L
    // This will later cause waiting tasks to wake up and check numTasks again
    lock.notifyAll()
  }

  // Keep looping until we're either sure that we don't want to grant this request (because this
  // task would have more than 1 / numActiveTasks of the memory) or we have enough free
  // memory to give it (we always let each task get at least 1 / (2 * numActiveTasks)).
  // TODO: simplify this to limit each task to its own slot
  while (true) {
    val numActiveTasks = memoryForTask.keys.size
    val curMem = memoryForTask(taskAttemptId)

    // In every iteration of this loop, we should first try to reclaim any borrowed execution
    // space from storage. This is necessary because of the potential race condition where new
    // storage blocks may steal the free execution memory that this task was waiting for.
    maybeGrowPool(numBytes - memoryFree)

    // Maximum size the pool would have after potentially growing the pool.
    // This is used to compute the upper bound of how much memory each task can occupy. This
    // must take into account potential free memory as well as the amount this pool currently
    // occupies. Otherwise, we may run into SPARK-12155 where, in unified memory management,
    // we did not take into account space that could have been freed by evicting cached blocks.
    val maxPoolSize = computeMaxPoolSize()
    val maxMemoryPerTask = maxPoolSize / numActiveTasks
    val minMemoryPerTask = poolSize / (2 * numActiveTasks)

    // How much we can grant this task; keep its share within 0 <= X <= 1 / numActiveTasks
    val maxToGrant = math.min(numBytes, math.max(0, maxMemoryPerTask - curMem))
    // Only give it as much memory as is free, which might be none if it reached 1 / numTasks
    val toGrant = math.min(maxToGrant, memoryFree)

    // We want to let each task get at least 1 / (2 * numActiveTasks) before blocking;
    // if we can't give it this much now, wait for other tasks to free up memory
    // (this happens if older tasks allocated lots of memory before N grew)
    if (toGrant < numBytes && curMem + toGrant < minMemoryPerTask) {
      logInfo(s"TID $taskAttemptId waiting for at least 1/2N of $poolName pool to be free")
      lock.wait()
    } else {
      memoryForTask(taskAttemptId) += toGrant
      return toGrant
    }
  }
  0L  // Never reached
}
```
é¦–å…ˆå…³æ³¨ä¸€ä¸‹é”çš„å¯¹è±¡ï¼Œåœ¨è°ƒç”¨æ–¹`MemoryManager`åˆå§‹åŒ–çš„æ—¶å€™æœ‰å£°æ˜é”çš„å¯¹è±¡ï¼š
```scala
@GuardedBy("this")
protected val onHeapStorageMemoryPool = new StorageMemoryPool(this, MemoryMode.ON_HEAP)
@GuardedBy("this")
protected val offHeapStorageMemoryPool = new StorageMemoryPool(this, MemoryMode.OFF_HEAP)
@GuardedBy("this")
protected val onHeapExecutionMemoryPool = new ExecutionMemoryPool(this, MemoryMode.ON_HEAP)
@GuardedBy("this")
protected val offHeapExecutionMemoryPool = new ExecutionMemoryPool(this, MemoryMode.OFF_HEAP)
```

```scala
private[memory] class ExecutionMemoryPool(
    lock: Object,
    memoryMode: MemoryMode
  )
```
é€šè¿‡ä¸Šé¢ä¸¤ä¸ªä»£ç ç‰‡æ®µå¯ä»¥çœ‹å‡ºï¼Œå¤šä¸ªPoolçš„é”å¯¹è±¡éƒ½æ˜¯`MemoryManger`ï¼Œæ‰€ä»¥å¤šä¸ªPoolä¹‹é—´æ˜¯äº’æ–¥çš„ï¼Œä¸è®ºæ˜¯`StorageMemoryPool`è¿˜æ˜¯`ExecutionMemoryPool`ã€‚

ç„¶åæ•´ä¸ªå‡½æ•°çš„å·¥ä½œæ–¹å¼ï¼š
* å¦‚æœæ˜¯ä¸€ä¸ªæ–°çš„taskï¼Œå…ˆå¸®å®ƒåŠ å…¥åˆ°`memoryForTask`ä¸­ï¼Œå†…å­˜è®¾ä¸º0ï¼Œç„¶åå”¤é†’æ‰€æœ‰ç­‰å¾…é˜Ÿåˆ—é‡Œçš„çº¿ç¨‹å¼€å§‹ç­‰é”ã€‚`memoryForTask `æ˜¯ä¸€ä¸ªä¿å­˜`taskId -> memory`çš„mapã€‚
* è¿›å…¥ä¸€ä¸ªæ­»å¾ªç¯ä¸­ï¼Œå…ˆæŸ¥çœ‹æ˜¯å¦éœ€è¦è·å–æ›´å¤šçš„å†…å­˜ï¼Œå¦‚æœéœ€è¦çš„è¯åˆ™è°ƒç”¨`maybeGrowPool`å›è°ƒã€‚è®¡ç®—ä¸€ä¸ªtaskç†è®ºèƒ½åˆ†é…åˆ°çš„æœ€å¤§å†…å­˜å’Œæœ€å°å†…å­˜ï¼Œå³`1/2N * maxPoolSize <= cache <= 1/N * maxPoolSize`ã€‚æ¥ç€è®¡ç®—å®é™…æœ€å¤§èƒ½åˆ†é…åˆ°çš„å†…å­˜ä»¥åŠæœ€ç»ˆå®é™…åˆ†é…çš„å†…å­˜ã€‚
* å¦‚æœå®é™…åˆ†é…åˆ°çš„å†…å­˜å°äºéœ€è¦çš„å†…å­˜æˆ–è€…è¿™ä¸ªä»»åŠ¡åˆ†é…åˆ°çš„æ€»å†…å­˜éƒ½æ²¡æœ‰è¾¾åˆ°ç†è®ºæœ€å°å†…å­˜çš„è¯ï¼Œåˆ™å°†é”è¿˜æ‰ä»¥åç»§ç»­ç­‰é”ã€‚å¦‚æœæ‹¿åˆ°äº†éœ€è¦çš„å†…å­˜ä»¥åå°±æ›´æ–°`memoryForTask`å¹¶è¿›è¡Œè¿”å›ã€‚

::acquireStorageMemory::
```scala
override def acquireStorageMemory(
    blockId: BlockId,
    numBytes: Long,
    memoryMode: MemoryMode): Boolean = synchronized {
  assertInvariants()
  assert(numBytes >= 0)
  val (executionPool, storagePool, maxMemory) = memoryMode match {
    case MemoryMode.ON_HEAP => (
      onHeapExecutionMemoryPool,
      onHeapStorageMemoryPool,
      maxOnHeapStorageMemory)
    case MemoryMode.OFF_HEAP => (
      offHeapExecutionMemoryPool,
      offHeapStorageMemoryPool,
      maxOffHeapStorageMemory)
  }
  if (numBytes > maxMemory) {
    // Fail fast if the block simply won't fit
    logInfo(s"Will not store $blockId as the required space ($numBytes bytes) exceeds our " +
      s"memory limit ($maxMemory bytes)")
    return false
  }
  if (numBytes > storagePool.memoryFree) {
    // There is not enough free memory in the storage pool, so try to borrow free memory from
    // the execution pool.
    val memoryBorrowedFromExecution = Math.min(executionPool.memoryFree,
      numBytes - storagePool.memoryFree)
    executionPool.decrementPoolSize(memoryBorrowedFromExecution)
    storagePool.incrementPoolSize(memoryBorrowedFromExecution)
  }
  storagePool.acquireMemory(blockId, numBytes)
}
```
å¦‚æœéœ€è¦ç”³è¯·çš„å†…å­˜å¤§äºæœ€å¤§å†…å­˜åˆ™è¿”å›falseï¼Œç”³è¯·çš„å†…å­˜å¤§äºStorageåŒºçš„å‰©ä½™å†…å­˜ï¼Œåˆ™éœ€è¦ä»ExecutionåŒºå€Ÿå†…å­˜ã€‚StorageåŒºä¸èƒ½å°†æ­£åœ¨è¿è¡Œçš„taskè¸¢å‡ºExecutionåŒºï¼Œæ‰€ä»¥åªèƒ½ä»ä¸­è·å–ç©ºé—²çš„ç©ºé—´å¤§å°ã€‚æ•°å€¼è®¡ç®—å®Œæˆä»¥åï¼Œå¼€å§‹çœŸæ­£çš„åˆ†é…ã€‚

```scala
def acquireMemory(
    blockId: BlockId,
    numBytesToAcquire: Long,
    numBytesToFree: Long): Boolean = lock.synchronized {
  assert(numBytesToAcquire >= 0)
  assert(numBytesToFree >= 0)
  assert(memoryUsed <= poolSize)
  if (numBytesToFree > 0) {
    memoryStore.evictBlocksToFreeSpace(Some(blockId), numBytesToFree, memoryMode)
  }
  // NOTE: If the memory store evicts blocks, then those evictions will synchronously call
  // back into this StorageMemoryPool in order to free memory. Therefore, these variables
  // should have been updated.
  val enoughMemory = numBytesToAcquire <= memoryFree
  if (enoughMemory) {
    _memoryUsed += numBytesToAcquire
  }
  enoughMemory
}
```
å…ˆä»Storageä¸­åˆ é™¤ä¸€äº›Blocké‡Šæ”¾ä¸€äº›å†…å­˜ï¼Œå¦‚æœæœ‰è¶³å¤Ÿçš„å†…å­˜ç”³è¯·å°±æ›´æ–°å·²ä½¿ç”¨çš„å†…å­˜è®¡æ•°å™¨ï¼Œå¦åˆ™ç›´æ¥è¿”å›falseã€‚

### MemoryPool
è¿™æ˜¯ä¸€ä¸ªæŠ½è±¡ç±»ï¼Œæ•´ä¸ªç±»éƒ½åœ¨ç»´æŠ¤ä¸€ä¸ªå˜é‡`_poolSize`ï¼Œè¡¨ç¤ºå†…å­˜ä½¿ç”¨é‡ã€‚æä¾›äº†ç»´æŠ¤è¿™ä¸ªé‡çš„ä¸€äº›æ–¹æ³•ï¼Œå¦‚ï¼š
* `poolSize: Long`ï¼šè·å–`_poolSize`
* `memoryFree: Long`ï¼šè·å–ç©ºé—²çš„å†…å­˜ç©ºé—´å¤§å°
* `incrementPoolSize(delta: Long)`ï¼šæé«˜`_poolSize`
* `decrementPoolSize(delta: Long)`ï¼šé™ä½`_poolSize`

ä»¥åŠä¸€ä¸ªæŠ½è±¡æ–¹æ³•ï¼š
- `memoryUsed: Long`

### ExecutionMemoryPool
è¯¥ç±»ä¸­ç»´æŠ¤äº†ä¸€ä¸ª`taskId -> memory`çš„Mapï¼š`memoryForTask`æ¥ç®¡ç†å†…å­˜ã€‚

```scala
override def memoryUsed: Long = lock.synchronized {
  memoryForTask.values.sum
}
```
å®ç°çˆ¶ç±»çš„æŠ½è±¡æ–¹æ³•ï¼Œç›´æ¥å°†`memoryForTask`ä¸­çš„valuesç´¯åŠ ã€‚

`acquireMemory`å·²ç»åœ¨ä¸Šæ–‡ä¸­åˆ†æè¿‡äº†ã€‚`releaseMemory`åœ¨`MemoryManager.releaseExecutionMemory`ä¸­è¢«è°ƒç”¨ï¼š
```scala
def releaseMemory(numBytes: Long, taskAttemptId: Long): Unit = lock.synchronized {
  val curMem = memoryForTask.getOrElse(taskAttemptId, 0L)
  val memoryToFree = if (curMem < numBytes) {
    logWarning(
      s"Internal error: release called on $numBytes bytes but task only has $curMem bytes " +
        s"of memory from the $poolName pool")
    curMem
  } else {
    numBytes
  }
  if (memoryForTask.contains(taskAttemptId)) {
    memoryForTask(taskAttemptId) -= memoryToFree
    if (memoryForTask(taskAttemptId) <= 0) {
      memoryForTask.remove(taskAttemptId)
    }
  }
  lock.notifyAll() // Notify waiters in acquireMemory() that memory has been freed
}
```
åœ¨æ­£å¼é‡Šæ”¾ä¹‹å‰ä¼šå…ˆæ¯”è¾ƒä¸€ä¸‹ç°åœ¨è¯¥taskæ‰€å ç”¨çš„å†…å­˜å’Œéœ€è¦é‡Šæ”¾çš„å†…å­˜çš„å¤§å°ï¼Œå¦‚æœtaskæ‰€å å†…å­˜å°äºéœ€è¦é‡Šæ”¾çš„å†…å­˜ä¹Ÿåªä¼šé‡Šæ”¾taskæ‰€å å†…å­˜ï¼Œä¸ä¼šå†é‡Šæ”¾å…¶ä»–çš„taskã€‚å› ä¸ºæœ‰æ–°çš„å†…å­˜ç©ºé—´å‡ºç°ï¼Œæ‰€ä»¥å¯ä»¥å”¤é†’ç­‰å¾…é˜Ÿåˆ—é‡Œçš„çº¿ç¨‹ï¼Œå¼€å§‹ç»™æ–°ä»»åŠ¡äº‰å–å†…å­˜ã€‚

```scala
def releaseAllMemoryForTask(taskAttemptId: Long): Long = lock.synchronized {
  val numBytesToFree = getMemoryUsageForTask(taskAttemptId)
  releaseMemory(numBytesToFree, taskAttemptId)
  numBytesToFree
}
```
è¯¥æ–¹æ³•ä¼šé‡Šæ”¾ä¸€ä¸ªtaskæ‰€æœ‰çš„å†…å­˜ï¼Œç›´æ¥è·å–taskæ‰€å ç”¨çš„å†…å­˜ä»¥åè°ƒç”¨ä¸Šé¢çš„`releaseMemory`æ–¹æ³•ã€‚

### StorageMemoryPool
è¯¥ç±»è´Ÿè´£StorageåŒºçš„å†…å­˜ç®¡ç†ï¼Œåœ¨ç±»ä¸­ç»´æŠ¤äº†ä¸€ä¸ª`_memoryUsed`å‚æ•°ï¼Œæ¥è¡¨ç¤ºä½¿ç”¨äº†å¤šå°‘å†…å­˜ã€‚å¹¶ä¸”ä¼šå…³è”ä¸€ä¸ª`MemoryStore`å¯¹è±¡ï¼Œè¯¥å¯¹è±¡ä¼šå®ŒæˆçœŸæ­£çš„å†…å­˜ç®¡ç†æ“ä½œã€‚

é‡è¦çš„`acquireMemory`å’Œ`freeSpaceToShrinkPool`å‡½æ•°å‡åœ¨ä¸Šæ–‡ä¸­è¿›è¡Œäº†ä»‹ç»ã€‚

### TaskMemoryManager
è¯¥ç±»è´Ÿè´£ç®¡ç†ä¸€ä¸ªtaskçš„å†…å­˜ï¼Œè¯¥ç±»ä¸­ä¸ä¼šç›´æ¥æ“ä½œå†…å­˜ï¼Œä¼šé€šè¿‡`MemoryManager`æ¥è¿›è¡Œç®¡ç†ã€‚ä¸è¿‡å› ä¸ºåº•å±‚ä½¿ç”¨äº†`Tungsten`å†…å­˜æ¨¡å‹ï¼Œè¯¥ç±»ä¸­è¿˜ä¼šç»´æŠ¤å†…å­˜æ¨¡å‹ä½¿ç”¨çš„é¡µæœºåˆ¶ç›¸å…³çš„å˜é‡ã€‚æ‰€æœ‰çš„`TaskMemoryManager`ä¼šå…±ç”¨ä¸€ä¸ª`MemoryManager`ã€‚

```java
public long acquireExecutionMemory(long required, MemoryConsumer consumer) {
  assert(required >= 0);
  assert(consumer != null);
  MemoryMode mode = consumer.getMode();
  // If we are allocating Tungsten pages off-heap and receive a request to allocate on-heap
  // memory here, then it may not make sense to spill since that would only end up freeing
  // off-heap memory. This is subject to change, though, so it may be risky to make this
  // optimization now in case we forget to undo it late when making changes.
  synchronized (this) {
    long got = memoryManager.acquireExecutionMemory(required, taskAttemptId, mode);

    // Try to release memory from other consumers first, then we can reduce the frequency of
    // spilling, avoid to have too many spilled files.
    if (got < required) {
      // Call spill() on other consumers to release memory
      // Sort the consumers according their memory usage. So we avoid spilling the same consumer
      // which is just spilled in last few times and re-spilling on it will produce many small
      // spill files.
      TreeMap<Long, List<MemoryConsumer>> sortedConsumers = new TreeMap<>();
      for (MemoryConsumer c: consumers) {
        if (c != consumer && c.getUsed() > 0 && c.getMode() == mode) {
          long key = c.getUsed();
          List<MemoryConsumer> list =
              sortedConsumers.computeIfAbsent(key, k -> new ArrayList<>(1));
          list.add(c);
        }
      }
      while (!sortedConsumers.isEmpty()) {
        // Get the consumer using the least memory more than the remaining required memory.
        Map.Entry<Long, List<MemoryConsumer>> currentEntry =
          sortedConsumers.ceilingEntry(required - got);
        // No consumer has used memory more than the remaining required memory.
        // Get the consumer of largest used memory.
        if (currentEntry == null) {
          currentEntry = sortedConsumers.lastEntry();
        }
        List<MemoryConsumer> cList = currentEntry.getValue();
        MemoryConsumer c = cList.get(cList.size() - 1);
        try {
          long released = c.spill(required - got, consumer);
          if (released > 0) {
            logger.debug("Task {} released {} from {} for {}", taskAttemptId,
              Utils.bytesToString(released), c, consumer);
            got += memoryManager.acquireExecutionMemory(required - got, taskAttemptId, mode);
            if (got >= required) {
              break;
            }
          } else {
            cList.remove(cList.size() - 1);
            if (cList.isEmpty()) {
              sortedConsumers.remove(currentEntry.getKey());
            }
          }
        } catch (ClosedByInterruptException e) {
          // This called by user to kill a task (e.g: speculative task).
          logger.error("error while calling spill() on " + c, e);
          throw new RuntimeException(e.getMessage());
        } catch (IOException e) {
          logger.error("error while calling spill() on " + c, e);
          // checkstyle.off: RegexpSinglelineJava
          throw new SparkOutOfMemoryError("error while calling spill() on " + c + " : "
            + e.getMessage());
          // checkstyle.on: RegexpSinglelineJava
        }
      }
    }

    // call spill() on itself
    if (got < required) {
      try {
        long released = consumer.spill(required - got, consumer);
        if (released > 0) {
          logger.debug("Task {} released {} from itself ({})", taskAttemptId,
            Utils.bytesToString(released), consumer);
          got += memoryManager.acquireExecutionMemory(required - got, taskAttemptId, mode);
        }
      } catch (ClosedByInterruptException e) {
        // This called by user to kill a task (e.g: speculative task).
        logger.error("error while calling spill() on " + consumer, e);
        throw new RuntimeException(e.getMessage());
      } catch (IOException e) {
        logger.error("error while calling spill() on " + consumer, e);
        // checkstyle.off: RegexpSinglelineJava
        throw new SparkOutOfMemoryError("error while calling spill() on " + consumer + " : "
          + e.getMessage());
        // checkstyle.on: RegexpSinglelineJava
      }
    }

    consumers.add(consumer);
    logger.debug("Task {} acquired {} for {}", taskAttemptId, Utils.bytesToString(got), consumer);
    return got;
  }
}
```
è¯¥æ–¹æ³•æ˜¯ä¸ºä¸€ä¸ªtaskæ–°çš„consumeråˆ†é…å†…å­˜ï¼Œä¸€è¿›æ¥ä¼šå…ˆå°è¯•ä½¿ç”¨ExecutorPoolç”³è¯·`required`å¤§å°çš„å†…å­˜ï¼Œå¦‚æœèƒ½ç›´æ¥è·å–åˆ°å°±ç»“æŸã€‚å¦åˆ™çš„è¯éœ€è¦ä»consumerä¸­æŒ‘é€‰åˆé€‚çš„consumerè¿›è¡Œspillæ“ä½œï¼ˆä¹Ÿå°±æ˜¯å°†å†…å­˜ä¸­çš„æ•°æ®å†²å†™åˆ°ç¡¬ç›˜ä¸Šï¼‰æ¥é‡Šæ”¾è¶³å¤Ÿå¤šçš„å†…å­˜ã€‚

æŒ‘é€‰çš„è¿‡ç¨‹ä¹Ÿå¾ˆå¸¸è§„ï¼Œä¼šé€‰å‡ºå¤§äºéœ€è¦çš„å†…å­˜çš„consumerä¸­æœ€å°çš„ä¸€ä¸ªï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä»å¤§åˆ°å°ä¾æ¬¡spillï¼Œç›´åˆ°é‡Šæ”¾çš„å†…å­˜è¾¾åˆ°éœ€æ±‚ã€‚ä¸è¿‡ç­›é€‰å¤§äºéœ€è¦çš„å†…å­˜ä¸­æœ€å°çš„ä¸€ä¸ªç”¨äº†ä¸€ä¸ªå¾ˆç®€æ´å¿«é€Ÿçš„æ–¹å¼ï¼Œåˆ›å»ºäº†ä¸€ä¸ª`memory -> List<MemoryConsumer>`çš„TreeMapï¼Œç›´æ¥ä½¿ç”¨`TreeMap.ceilingEntry`æ–¹æ³•ã€‚æ¯æ¬¡é‡Šæ”¾å®Œæˆä»¥åéƒ½å†é‡æ–°ç”³è¯·æ›´å¤šçš„å†…å­˜ï¼Œç›´åˆ°ç”³è¯·åˆ°äº†è¶³å¤Ÿå¤šçš„å†…å­˜ã€‚

å¦‚æœåœ¨ä¸Šé¢çš„æ“ä½œæ‰§è¡Œå®Œæˆä»¥åï¼ˆä¹Ÿå°±æ˜¯èƒ½é‡Šæ”¾çš„éƒ½é‡Šæ”¾æ‰äº†ï¼‰è¿˜æ˜¯ä¸å¤Ÿï¼Œé‚£ä¹ˆå°±å°†è¿™ä¸ªè¦åŠ å…¥çš„æ–°çš„consumerçš„éƒ¨åˆ†æ•°æ®å†²å†™åˆ°ç¡¬ç›˜ä¸Šï¼Œä½¿ä»–èƒ½è¢«æ”¾å…¥MemoryPoolä¸­ã€‚

#### Allocate page
```java
public MemoryBlock allocatePage(long size, MemoryConsumer consumer) {
  assert(consumer != null);
  assert(consumer.getMode() == tungstenMemoryMode);
  if (size > MAXIMUM_PAGE_SIZE_BYTES) {
    throw new TooLargePageException(size);
  }

  long acquired = acquireExecutionMemory(size, consumer);
  if (acquired <= 0) {
    return null;
  }

  final int pageNumber;
  synchronized (this) {
    pageNumber = allocatedPages.nextClearBit(0);
    if (pageNumber >= PAGE_TABLE_SIZE) {
      releaseExecutionMemory(acquired, consumer);
      throw new IllegalStateException(
        "Have already allocated a maximum of " + PAGE_TABLE_SIZE + " pages");
    }
    allocatedPages.set(pageNumber);
  }
  MemoryBlock page = null;
  try {
    page = memoryManager.tungstenMemoryAllocator().allocate(acquired);
  } catch (OutOfMemoryError e) {
    logger.warn("Failed to allocate a page ({} bytes), try again.", acquired);
    // there is no enough memory actually, it means the actual free memory is smaller than
    // MemoryManager thought, we should keep the acquired memory.
    synchronized (this) {
      acquiredButNotUsed += acquired;
      allocatedPages.clear(pageNumber);
    }
    // this could trigger spilling to free some pages.
    return allocatePage(size, consumer);
  }
  page.pageNumber = pageNumber;
  pageTable[pageNumber] = page;
  if (logger.isTraceEnabled()) {
    logger.trace("Allocate page number {} ({} bytes)", pageNumber, acquired);
  }
  return page;
}
```
é¡µç®¡ç†ä¸»è¦ç”±ä¸€ä¸ª `BitSet`ï¼ˆæ ‡ç¤ºé¡µä½æƒ…å†µï¼‰å’Œ`MemoryBlock[]`ï¼ˆï¼‰å®ç°ï¼Œtrueè¡¨ç¤ºé¡µä½è¢«å ã€‚è¯¥æ–¹æ³•ä¼šå…ˆè°ƒç”¨`acquireExecutionMemory`ç”³è¯·å®é™…çš„ç‰©ç†å†…å­˜ï¼Œç„¶åé€šè¿‡`BitSet.nextClearBitï¼ˆï¼‰`å‡½æ•°è·å–ç¬¬ä¸€ä¸ªç©ºä½ç½®ï¼Œå¹¶è¿›è¡Œå ä½ã€‚å®Œæˆä»¥åå°±ä¼šé€šè¿‡`tungstenMemoryAllocator`æ¥çœŸæ­£è¿›è¡Œå†…å­˜ç”³è¯·ï¼Œä¸‹é¢ä¼šåˆ†æä¸€ä¸‹on-heapå’Œoff-heapä¸¤ç§ä¸åŒçš„å†…å­˜ç”³è¯·ï¼š

::Unsafe memory allocate::
```java
public MemoryBlock allocate(long size) throws OutOfMemoryError {
  long address = Platform.allocateMemory(size);
  MemoryBlock memory = new MemoryBlock(null, address, size);
  if (MemoryAllocator.MEMORY_DEBUG_FILL_ENABLED) {
    memory.fill(MemoryAllocator.MEMORY_DEBUG_FILL_CLEAN_VALUE);
  }
  return memory;
}
```
Off-heapçš„æ‰€æœ‰å†…å­˜æ“ä½œéƒ½æ˜¯é€šè¿‡Unsafeå·¥å…·ç±»æ¥å®Œæˆï¼Œè¿™ä¸ªæ–¹æ³•éå¸¸çš„ç®€å•ã€‚ä¼šå…ˆé€šè¿‡`Unsafe.allocateMemory`ç”³è¯·å†…å­˜ï¼Œç„¶ååˆå§‹åŒ–ä¸€ä¸ªé¡µç»“æ„ï¼Œoff-heapä¸ä¼šæ˜ å°„å¯¹è±¡ï¼Œæ‰€ä»¥objä¼ å…¥nullå³å¯ã€‚

::Heap memory allocate::
```java
public MemoryBlock allocate(long size) throws OutOfMemoryError {
  int numWords = (int) ((size + 7) / 8);
  long alignedSize = numWords * 8L;
  assert (alignedSize >= size);
  if (shouldPool(alignedSize)) {
    synchronized (this) {
      final LinkedList<WeakReference<long[]>> pool = bufferPoolsBySize.get(alignedSize);
      if (pool != null) {
        while (!pool.isEmpty()) {
          final WeakReference<long[]> arrayReference = pool.pop();
          final long[] array = arrayReference.get();
          if (array != null) {
            assert (array.length * 8L >= size);
            MemoryBlock memory = new MemoryBlock(array, Platform.LONG_ARRAY_OFFSET, size);
            if (MemoryAllocator.MEMORY_DEBUG_FILL_ENABLED) {
              memory.fill(MemoryAllocator.MEMORY_DEBUG_FILL_CLEAN_VALUE);
            }
            return memory;
          }
        }
        bufferPoolsBySize.remove(alignedSize);
      }
    }
  }
  long[] array = new long[numWords];
  MemoryBlock memory = new MemoryBlock(array, Platform.LONG_ARRAY_OFFSET, size);
  if (MemoryAllocator.MEMORY_DEBUG_FILL_ENABLED) {
    memory.fill(MemoryAllocator.MEMORY_DEBUG_FILL_CLEAN_VALUE);
  }
  return memory;
}
```
è¿™é‡Œå¤šå¤§å†…å­˜æœ‰ä¸€ä¸ªä¼˜åŒ–æœºåˆ¶ï¼Œç±»ä¸­æœ‰ä¸€ä¸ªMapä¼šä¿å­˜å¤§å†…å­˜å—çš„å¼•ç”¨ï¼Œå‡å°‘GCå’Œç”³è¯·å†…å­˜çš„æ—¶é—´ã€‚
```java
@GuardedBy("this")
private final Map<Long, LinkedList<WeakReference<long[]>>> bufferPoolsBySize = new HashMap<>();
```
è§¦å‘è¿™ä¸ªæœºåˆ¶çš„å†…å­˜å¤§å°æ˜¯`1024 * 1024`ï¼Œæ‰€ä»¥æˆ‘ä»¬èƒ½çœ‹åˆ°åœ¨allocateæ–¹æ³•ä¸­ä¼šå…ˆåˆ¤æ–­æ˜¯å¦è§¦å‘è¯¥æœºåˆ¶ï¼Œå¦‚æœè§¦å‘åˆ™ä»æœªè¢«å›æ”¶çš„å¤§å†…å­˜å—ä¸­å–å‡ºç›¸åº”çš„å—è¿›è¡Œå­˜å‚¨ï¼Œå¦åˆ™ä¼šé‡æ–°ç”³è¯·å†…å­˜ã€‚

#### Free page
```java
public void freePage(MemoryBlock page, MemoryConsumer consumer) {
  assert (page.pageNumber != MemoryBlock.NO_PAGE_NUMBER) :
    "Called freePage() on memory that wasn't allocated with allocatePage()";
  assert (page.pageNumber != MemoryBlock.FREED_IN_ALLOCATOR_PAGE_NUMBER) :
    "Called freePage() on a memory block that has already been freed";
  assert (page.pageNumber != MemoryBlock.FREED_IN_TMM_PAGE_NUMBER) :
          "Called freePage() on a memory block that has already been freed";
  assert(allocatedPages.get(page.pageNumber));
  pageTable[page.pageNumber] = null;
  synchronized (this) {
    allocatedPages.clear(page.pageNumber);
  }
  if (logger.isTraceEnabled()) {
    logger.trace("Freed page number {} ({} bytes)", page.pageNumber, page.size());
  }
  long pageSize = page.size();
  // Clear the page number before passing the block to the MemoryAllocator's free().
  // Doing this allows the MemoryAllocator to detect when a TaskMemoryManager-managed
  // page has been inappropriately directly freed without calling TMM.freePage().
  page.pageNumber = MemoryBlock.FREED_IN_TMM_PAGE_NUMBER;
  memoryManager.tungstenMemoryAllocator().free(page);
  releaseExecutionMemory(pageSize, consumer);
}
```
å¯¹åº”äºç”³è¯·é¡µä¹Ÿä¼šæœ‰é‡Šæ”¾é¡µçš„æ“ä½œï¼Œè¿™ä¸ªè¿‡ç¨‹æ¯”è¾ƒç®€å•ï¼Œå°±æ˜¯å¯¹é¡µç›¸å…³çš„æ•°æ®ç»“æ„è¿›è¡Œæ›´æ–°ï¼Œåšä¸€äº›æ¸…ç©ºæ“ä½œã€‚æœ€åä¼šè°ƒç”¨`tungstenMemoryAllocator.free`è¿›è¡ŒçœŸæ­£çš„é‡Šæ”¾ï¼Œå¹¶ä¸”è°ƒç”¨åº•å±‚çš„ExecutoråŒºçš„poolè¿›è¡Œé‡Šæ”¾ã€‚ä¸‹é¢ä¹Ÿä¼šåˆ†æä¸€ä¸‹on-heapå’Œoff-heapçš„ä¸åŒé‡Šæ”¾æ“ä½œã€‚

::Unsafe memory free::
```java
public void free(MemoryBlock memory) {
  assert (memory.obj == null) :
    "baseObject not null; are you trying to use the off-heap allocator to free on-heap memory?";
  assert (memory.pageNumber != MemoryBlock.FREED_IN_ALLOCATOR_PAGE_NUMBER) :
    "page has already been freed";
  assert ((memory.pageNumber == MemoryBlock.NO_PAGE_NUMBER)
          || (memory.pageNumber == MemoryBlock.FREED_IN_TMM_PAGE_NUMBER)) :
    "TMM-allocated pages must be freed via TMM.freePage(), not directly in allocator free()";

  if (MemoryAllocator.MEMORY_DEBUG_FILL_ENABLED) {
    memory.fill(MemoryAllocator.MEMORY_DEBUG_FILL_FREED_VALUE);
  }
  Platform.freeMemory(memory.offset);
  // As an additional layer of defense against use-after-free bugs, we mutate the
  // MemoryBlock to reset its pointer.
  memory.offset = 0;
  // Mark the page as freed (so we can detect double-frees).
  memory.pageNumber = MemoryBlock.FREED_IN_ALLOCATOR_PAGE_NUMBER;
}
```
æ•´ä¸ªè¿‡ç¨‹ä¹Ÿå¾ˆç®€å•ï¼Œè°ƒç”¨`Unsafe.freeMemory`è¿›è¡Œå†…å­˜é‡Šæ”¾ï¼Œå°†é¡µå¯¹è±¡è®¾ç½®ä¸ºä¸€ä¸ªæ¸…ç©ºåçš„çŠ¶æ€ã€‚

::Heap memory free::
```java
public void free(MemoryBlock memory) {
  assert (memory.obj != null) :
    "baseObject was null; are you trying to use the on-heap allocator to free off-heap memory?";
  assert (memory.pageNumber != MemoryBlock.FREED_IN_ALLOCATOR_PAGE_NUMBER) :
    "page has already been freed";
  assert ((memory.pageNumber == MemoryBlock.NO_PAGE_NUMBER)
          || (memory.pageNumber == MemoryBlock.FREED_IN_TMM_PAGE_NUMBER)) :
    "TMM-allocated pages must first be freed via TMM.freePage(), not directly in allocator " +
      "free()";

  final long size = memory.size();
  if (MemoryAllocator.MEMORY_DEBUG_FILL_ENABLED) {
    memory.fill(MemoryAllocator.MEMORY_DEBUG_FILL_FREED_VALUE);
  }

  // Mark the page as freed (so we can detect double-frees).
  memory.pageNumber = MemoryBlock.FREED_IN_ALLOCATOR_PAGE_NUMBER;

  // As an additional layer of defense against use-after-free bugs, we mutate the
  // MemoryBlock to null out its reference to the long[] array.
  long[] array = (long[]) memory.obj;
  memory.setObjAndOffset(null, 0);

  long alignedSize = ((size + 7) / 8) * 8;
  if (shouldPool(alignedSize)) {
    synchronized (this) {
      LinkedList<WeakReference<long[]>> pool = bufferPoolsBySize.get(alignedSize);
      if (pool == null) {
        pool = new LinkedList<>();
        bufferPoolsBySize.put(alignedSize, pool);
      }
      pool.add(new WeakReference<>(array));
    }
  } else {
    // Do nothing
  }
}
```
å°†å†…å­˜åŒºåŸŸç½®ä¸ºç©ºï¼Œå¦‚æœæ˜¯ä¸€ä¸ªå¤§å†…å­˜å—çš„è¯å°±ä¿ç•™å¼±å¼•ç”¨ï¼Œä»¥ä¾›ä¸‹æ¬¡éœ€è¦çš„æ—¶å€™ç›´æ¥è¿›è¡Œä½¿ç”¨ã€‚ä¸ºäº†åŠ å¤§å‘½ä¸­æ¦‚ç‡å¯ä»¥çœ‹åˆ°åœ¨è®¡ç®—å ç”¨å†…å­˜çš„æ—¶å€™éƒ½ä¼šæ‰¾åˆ°æ¯”å½“å‰å†…å­˜å¤§çš„æœ€è¿‘çš„ä¸€ä¸ª8çš„å€æ•°ï¼Œä¿è¯äº†ä»å¼±å¼•ç”¨åŒºåŸŸä¸­æ‰¾åˆ°çš„ä¸€å®šæ˜¯è¶³å¤Ÿèƒ½è£…çš„ä¸‹æ•°æ®ä¸­æœ€å°çš„ä¸€å—ã€‚

## å‚è€ƒ
[spark æºç åˆ†æä¹‹åäº” â€” Sparkå†…å­˜ç®¡ç†å‰–æ - JohnnyBai - åšå®¢å›­](https://www.cnblogs.com/johnny666888/p/11197519.html)
[GitHub - hustnn/TungstenSecret: Explore the project Tungsten](https://github.com/hustnn/TungstenSecret)
[Java 6 thread states and life cycle UML protocol state machine diagram example.](https://www.uml-diagrams.org/examples/java-6-thread-state-machine-diagram-example.html)